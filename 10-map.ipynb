{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "# Maps\n",
    "\n",
    "## Agenda\n",
    "\n",
    "- Discussion: pros/cons of array-backed and linked structures\n",
    "- Comparison to `set` and `dict`\n",
    "- The **Map** ADT\n",
    "- Direct lookups via *Hashing*\n",
    "- Hashtables\n",
    "    - Collisions and the \"Birthday problem\"\n",
    "- Runtime analysis & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## Discussion: pros/cons of array-backed and linked structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "Between the array-backed and linked list we have:\n",
    "\n",
    "1. $O(1)$ indexing (array-backed)\n",
    "2. $O(1)$ appending (array-backed & linked)\n",
    "3. $O(1)$ insertion/deletion without indexing (linked)\n",
    "4. $O(N)$ linear search (unsorted)\n",
    "5. $O(\\log N)$ binary search, when sorted (only array-backed lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## Comparison to `set` and `dict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "The `set` and `dict` types don't support positional access (i.e., by index), but do support lookup/search. How fast do they fare compared to lists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "def lin_search(lst, x):\n",
    "    for y in lst:\n",
    "        if x == y:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def bin_search(lst, x):\n",
    "    # assumes lst is sorted\n",
    "    low = 0\n",
    "    hi  = len(lst)-1\n",
    "    while low <= hi:\n",
    "        mid = (low + hi) // 2\n",
    "        if x < lst[mid]:\n",
    "            hi  = mid - 1\n",
    "        elif x < lst[mid]:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 6] # set size of plot\n",
    "\n",
    "ns = np.linspace(100, 10_000, 50, dtype=int)\n",
    "\n",
    "ts_linsearch = [timeit.timeit('lin_search(lst, lst[-1])',\n",
    "                              setup=f'lst = list(range({n}))',\n",
    "                              globals=globals(),\n",
    "                              number=100)\n",
    "                for n in ns]\n",
    "\n",
    "ts_binsearch = [timeit.timeit('bin_search(lst, 0)',\n",
    "                              setup=f'lst = list(range({n}))',\n",
    "                              globals=globals(),\n",
    "                              number=100)\n",
    "                for n in ns]\n",
    "\n",
    "ts_setadd    = [timeit.timeit(f'st.add({n})',\n",
    "                              setup=f'st = set(range({n}))',\n",
    "                              globals=globals(),\n",
    "                              number=100)\n",
    "                for n in ns]\n",
    "\n",
    "\n",
    "ts_setsearch = [timeit.timeit(f'{0} in st', # try for other values\n",
    "                              setup=f'st = set(range({n}))',\n",
    "                              globals=globals(),\n",
    "                              number=100)\n",
    "                for n in ns]\n",
    "\n",
    "ts_dctadd    = [timeit.timeit(f'dct[{n}] = 0',\n",
    "                              setup=f'dct = {{x:x for x in range({n})}}',\n",
    "                              globals=globals(),\n",
    "                              number=100)\n",
    "                for n in ns]\n",
    "\n",
    "ts_dctsearch = [timeit.timeit(f'{0} in dct', # try for other values\n",
    "                              setup=f'dct = {{x:x for x in range({n})}}',\n",
    "                              globals=globals(),\n",
    "                              number=100)\n",
    "                for n in ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "plt.plot(ns, ts_linsearch, 'sr')\n",
    "plt.plot(ns, ts_binsearch, 'sg')\n",
    "plt.plot(ns, ts_setadd, 'db')\n",
    "plt.plot(ns, ts_setsearch, 'ob')\n",
    "plt.plot(ns, ts_dctadd, 'dm');\n",
    "plt.plot(ns, ts_dctsearch, 'om');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "Somehow, by discarding positional access and manipulation, sets and dictionaries appear to be able to implement insertion and search in **constant time**!\n",
    "\n",
    "How is this magic possible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## The **Map** ADT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "We will focus next on the \"*map*\" abstract data type (aka \"associative array\" or \"dictionary\"), which is used to associate keys (which must be unique) with values. \n",
    "\n",
    "A map *does not* intrinsically impose any ordering on its contents --- i.e., an implementation of a map does not need to support positional access to keys, nor report a consistent view of key order.\n",
    "\n",
    "Python's `dict` type is an implementation of the map ADT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### But what about sets?\n",
    "\n",
    "Given an implementation of a map, it should be straightforward to use it to implement a set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySet:\n",
    "    def __init__(self):\n",
    "        self.dct = dict()\n",
    "    \n",
    "    def add(self, value):\n",
    "        pass\n",
    "    \n",
    "    def __contains__(self, value):\n",
    "        pass\n",
    "        \n",
    "    def intersection(self, other):\n",
    "        assert isinstance(other, MySet)\n",
    "        pass\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.dct)\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return '{' + ', '.join(repr(x) for x in self) + '}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = MySet()\n",
    "\n",
    "for c in 'hello world!':\n",
    "    st.add(c)\n",
    "\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set('hello world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st2 = MySet()\n",
    "\n",
    "for c in 'farewell planet':\n",
    "    st2.add(c)\n",
    "    \n",
    "st.intersection(st2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set('hello world!') & set('farewell planet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple map implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "class MapDS:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        pass\n",
    "            \n",
    "    def __contains__(self, key):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "m = MapDS()\n",
    "m['batman'] = 'bruce wayne'\n",
    "m['superman'] = 'clark kent'\n",
    "m['spiderman'] = 'peter parker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "m['batman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "m['batman'] = 'tony stark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "m['batman']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "How can we make the leap from linear runtime complexity to constant?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## Direct lookups via *Hashing*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "Hashes (a.k.a. hash codes or hash values) are simply numerical values computed for objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "hash('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "hash('batman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "hash('batmen') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "[hash(s) for s in ['different', 'objects', 'have', 'very', 'different', 'hashes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "[hash(s)%100 for s in ['different', 'objects', 'have', 'very', 'different', 'hashes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `hash` function in Python is *randomized* by default -- i.e., each time a Python interpreter is fired up, the implementation of `hash` will use a different \"seed\" for the random number generator used in computing hashes. While hashcodes computed for a given value will be consistent for a given interpreter instance, they will not be across instances! This means we shouldn't save hashcodes for values to disk, or save them to a database, as values will almost certainly hash to different hashcodes after we restart our software!\n",
    "\n",
    "Why does Python do this? More later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## Hashtables\n",
    "\n",
    "A **hashtable** is an implementation of the map ADT that uses the hashcode for a key to compute an index into an array where the corresponding key/value pair will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "class Hashtable:\n",
    "    def __init__(self, n_buckets):\n",
    "        self.buckets = [None] * n_buckets\n",
    "        \n",
    "    def __setitem__(self, key, val):\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        pass\n",
    "        \n",
    "    def __contains__(self, key):\n",
    "        try:\n",
    "            _ = self[key]\n",
    "            return True\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht = Hashtable(100)\n",
    "ht['spiderman'] = 'peter parker'\n",
    "ht['batman'] = 'bruce wayne'\n",
    "ht['superman'] = 'clark kent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht['spiderman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht['batman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht['superman']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## On Collisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### The \"Birthday Problem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "Problem statement: Given $N$ people at a party, how likely is it that at least two people will have the same birthday?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Collision Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "def birthday_p(n_people):\n",
    "    p_inv = 1\n",
    "    for n in range(365, 365-n_people, -1):\n",
    "        p_inv *= n / 365\n",
    "    return 1 - p_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "birthday_p(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "1-364/365*363/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "n_people = range(1, 80)\n",
    "plt.plot(n_people, [birthday_p(n) for n in n_people]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### General collision statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "Repeat the birthday problem, but with a given number of values and \"buckets\" that are allotted to hold them. How likely is it that two or more values will map to the same bucket?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "def collision_p(n_values, n_buckets):\n",
    "    p_inv = 1\n",
    "    for n in range(n_buckets, n_buckets-n_values, -1):\n",
    "        p_inv *= n / n_buckets\n",
    "    return 1 - p_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "collision_p(23, 365) # same as birthday problem, for 23 people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "collision_p(10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "collision_p(100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# keeping number of values fixed at 100, but vary number of buckets: visualize probability of collision\n",
    "n_buckets = range(100, 100001, 1000)\n",
    "plt.plot(n_buckets, [collision_p(100, nb) for nb in n_buckets]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "def avg_num_collisions(n, b):\n",
    "    \"\"\"Returns the expected number of collisions for n values uniformly distributed\n",
    "    over a hashtable of b buckets. Based on (fairly) elementary probability theory.\n",
    "    (Pay attention in MATH 474!)\"\"\"\n",
    "    return n - b + b * (1 - 1/b)**n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "avg_num_collisions(28, 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "avg_num_collisions(1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "avg_num_collisions(1000, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## Dealing with Collisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "To deal with collisions in a hashtable, we simply create a \"chain\" of key/value pairs for each bucket where collisions occur. The chain needs to be a data structure that supports quick insertion — natural choice: the linked list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "class Hashtable:\n",
    "    class Node:\n",
    "        def __init__(self, key, val, next=None):\n",
    "            self.key = key\n",
    "            self.val = val\n",
    "            self.next = next\n",
    "            \n",
    "    def __init__(self, n_buckets=1000):\n",
    "        self.buckets = [None] * n_buckets\n",
    "        \n",
    "    def __setitem__(self, key, val):\n",
    "        bidx = hash(key) % len(self.buckets)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        bidx = hash(key) % len(self.buckets)\n",
    "    \n",
    "    def __contains__(self, key):\n",
    "        try:\n",
    "            _ = self[key]\n",
    "            return True\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht = Hashtable(100)\n",
    "ht['batman'] = 'bruce wayne'\n",
    "ht['superman'] = 'clark kent'\n",
    "ht['spiderman'] = 'peter parker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht['batman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht['superman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht['spiderman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "def init_ht(size):\n",
    "    ht = Hashtable(size)\n",
    "    for x in range(size):\n",
    "        ht[x] = x\n",
    "    return ht\n",
    "\n",
    "ns = np.linspace(100, 10_000, 50, dtype=int)\n",
    "ts_htsearch = [timeit.timeit(f'{0} in ht',\n",
    "                             setup='ht = init_ht({})'.format(n),\n",
    "                             globals=globals(),\n",
    "                             number=100)\n",
    "               for n in ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "plt.plot(ns, ts_binsearch, 'ro')\n",
    "plt.plot(ns, ts_htsearch, 'gs')\n",
    "plt.plot(ns, ts_dctsearch, 'b^');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## Loose ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "class Hashtable(Hashtable):\n",
    "    def __iter__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht = Hashtable(100)\n",
    "ht['batman'] = 'bruce wayne'\n",
    "ht['superman'] = 'clark kent'\n",
    "ht['spiderman'] = 'peter parker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "for k in ht:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### Key ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht = Hashtable()\n",
    "d = {}\n",
    "for x in 'apple banana cat dog elephant'.split():\n",
    "    d[x[0]] = x\n",
    "    ht[x[0]] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "for k in d:\n",
    "    print(k, '=>', d[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "for k in ht:\n",
    "    print(k, '=>', ht[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal",
    "tags": []
   },
   "source": [
    "### Load factor & Rehashing\n",
    "\n",
    "It is clear that the ratio of the number of keys to the number of buckets (known as the **load factor**) can have a significant effect on the performance of a hashtable.\n",
    "\n",
    "A fixed number of buckets doesn't make sense, as it might be wasteful for a small number of keys, and also scale poorly to a relatively large number of keys. And it also doesn't make sense to have the user of the hashtable manually specify the number of buckets (which is a low-level implementation detail). \n",
    "\n",
    "Instead: a practical hashtable implementation would start with a relatively small number of buckets, and if/when the load factor increases beyond some threshold (typically 1), it *dynamically increases the number of buckets* (typically to twice the previous number). This requires that all existing keys be *rehashed* to new buckets (why?).\n",
    "\n",
    "What is the runtime complexity of rehashing a hashtable of *N* keys?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### Uniform hashing\n",
    "\n",
    "Ultimately, the performance of a hashtable also heavily depends on hashcodes being *uniformly distributed* --- i.e., where, statistically, each bucket has roughly the same number of keys hashing to it. Designing hash functions that do this is an algorithmic problem that's outside the scope of this class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## Runtime analysis & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "For a hashtable with $N$ key/value entries, in the worst imaginable scenario all keys hash to the same bucket, and we end up having to navigate through a chain of $N$ collisions when inserting/searching/deleting, which gives us the  following *worst-case runtime complexities*:\n",
    "\n",
    "- Insertion: $O(N)$\n",
    "- Lookup: $O(N)$\n",
    "- Deletion: $O(N)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "BUT, if we assume uniform hashing and the rehashing behavior described above, it is possible to prove that hashtables have $O(1)$ *amortized (i.e., average) runtime complexity*. Proving this is also beyond the scope of this class (but is borne out by empirical data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denial of Service Attacks and Random Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashtables are unique in that they depend on good average case runtime complexity, and the incredibly low likelihood of a large number of collisions happening.\n",
    "\n",
    "But what if someone knew what different values hashed to in advance, and intentionally caused a huge number of keys to be entered into a hashtable that would result in collisions?\n",
    "\n",
    "This is the basis of a **denial of service attack** aimed at taking advantage of the worst-case runtime complexity of a Hashtable! The good news: Python makes this much more difficult by randomizing hashes by default -- but it also means you need to take care to guard your hash function if you implement one yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## Vocabulary list\n",
    "\n",
    "- hashtable\n",
    "- hashing and hashes\n",
    "- collision\n",
    "- hash buckets & chains\n",
    "- birthday problem\n",
    "- load factor\n",
    "- rehashing\n",
    "- denial of service attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## Addendum: On *Hashability*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "Remember: *a given object must always hash to the same value*. This is required so that we can always map the object to the same hash bucket.\n",
    "\n",
    "Hashcodes for collections of objects are usually computed from the hashcodes of its contents, e.g., the hash of a tuple is a function of the hashes of the objects in said tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "hash(('two', 'strings'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "This is useful. It allows us to use a tuple, for instance, as a key for a hashtable.\n",
    "\n",
    "However, if the collection of objects is *mutable* — i.e., we can alter its contents — this means that we can potentially change its hashcode.`\n",
    "\n",
    "If we were to use such a collection as a key in a hashtable, and alter the collection after it's been assigned to a particular bucket, this leads to a serious problem: the collection may now be in the wrong bucket (as it was assigned to a bucket based on its original hashcode)!\n",
    "\n",
    "For this reason, only immutable types are, by default, hashable in Python. So while we can use integers, strings, and tuples as keys in dictionaries, lists (which are mutable) cannot be used. Indeed, Python marks built-in mutable types as \"unhashable\", e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "hash([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "That said, Python does support hashing on instances of custom classes (which are mutable). This is because the default hash function implementation does not rely on the contents of instances of custom classes. E.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "class Student:\n",
    "    def __init__(self, fname, lname):\n",
    "        self.fname = fname\n",
    "        self.lname = lname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "s = Student('John', 'Doe')\n",
    "hash(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "s.fname = 'Jane'\n",
    "hash(s) # same as before mutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "We can change the default behavior by providing our own hash function in `__hash__`, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "class Student:\n",
    "    def __init__(self, fname, lname):\n",
    "        self.fname = fname\n",
    "        self.lname = lname\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash(self.fname) + hash(self.lname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "s = Student('John', 'Doe')\n",
    "hash(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "s.fname = 'Jane'\n",
    "hash(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "But be careful: instances of this class are no longer suitable for use as keys in hashtables (or dictionaries), if you intend to mutate them after using them as keys!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "mimir": {
   "data": {},
   "last_submission_id": "",
   "project_id": "aa73d4af-4b00-400e-8c6c-d83178fea3c6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
